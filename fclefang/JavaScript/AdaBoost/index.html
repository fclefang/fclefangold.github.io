<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>AdaBoost | fclefang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="鉴于之前入门机器学习的两个月学习起来很吃力，很难写出相对系统有意义的博客，从今天起，这一学期的接下来两个月会好好写下自己的学习总结，清晰头脑中的知识结构。任务：论文的阅读理解，机器学习知识的总结，机器学习实战代码的训练。
###1. AdaBoost起源介绍集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统。若多个分类器属于同种类型则这样">
<meta property="og:type" content="article">
<meta property="og:title" content="AdaBoost">
<meta property="og:url" content="http://www.fclef.me/fclefang/JavaScript/AdaBoost/index.html">
<meta property="og:site_name" content="fclefang">
<meta property="og:description" content="鉴于之前入门机器学习的两个月学习起来很吃力，很难写出相对系统有意义的博客，从今天起，这一学期的接下来两个月会好好写下自己的学习总结，清晰头脑中的知识结构。任务：论文的阅读理解，机器学习知识的总结，机器学习实战代码的训练。
###1. AdaBoost起源介绍集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统。若多个分类器属于同种类型则这样">
<meta property="og:updated_time" content="2016-11-14T02:54:02.953Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AdaBoost">
<meta name="twitter:description" content="鉴于之前入门机器学习的两个月学习起来很吃力，很难写出相对系统有意义的博客，从今天起，这一学期的接下来两个月会好好写下自己的学习总结，清晰头脑中的知识结构。任务：论文的阅读理解，机器学习知识的总结，机器学习实战代码的训练。
###1. AdaBoost起源介绍集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统。若多个分类器属于同种类型则这样">
  
    <link rel="alternative" href="/atom.xml" title="fclefang" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/fxy.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Fclefang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">开心自由最重要</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>About</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/categories">分类</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/MR-Fclef" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/fang-xiang-yan" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/JavaScript/" style="font-size: 15px;">JavaScript</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MachineLearning/" style="font-size: 20px;">MachineLearning</a> <a href="/tags/Node-js/" style="font-size: 12.5px;">Node.js</a> <a href="/tags/java/" style="font-size: 17.5px;">java</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">CIT（2012-2016）,GuiLin Elec(2016-2019).认真做好应该做的每一件事。衣不如新，人不如旧，旧衣穿着最舒服，新人也未必不是更好的选择...</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Fclefang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/img/fxy.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Fclefang</h1>
			</hgroup>
			
			<p class="header-subtitle">开心自由最重要</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/categories">分类</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/MR-Fclef" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/fang-xiang-yan" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-JavaScript/AdaBoost" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/fclefang/JavaScript/AdaBoost/" class="article-date">
  	<time datetime="2016-10-31T00:52:36.000Z" itemprop="datePublished">2016-10-31</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      AdaBoost
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/AdaBoost/">AdaBoost</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>鉴于之前入门机器学习的两个月学习起来很吃力，很难写出相对系统有意义的博客，从今天起，这一学期的接下来两个月会好好写下自己的学习总结，清晰头脑中的知识结构。<br>任务：论文的阅读理解，机器学习知识的总结，机器学习实战代码的训练。</strong></p>
<p>###1. AdaBoost起源介绍<br>集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统。若多个分类器属于同种类型则这样的集成是同质的，否则称之为异质。<a id="more"></a>同质(homogeneous)集成的个体学习器亦称为基学习器(base learner),异质的个体学习器一般称为组建学习器(component learner)。</p>
<ul>
<li>如何使集成学习获得比最好的单一学习器更好的性能呢？<br>要获得好的集成个体学习器应好而不同，即个体学习器要有一定的准确性，另外还要有多样性即学习器之间要有差异。事实上，个体学习器的准确性和多样性本身就存在冲突，一般准确性很高后，当要增加多样性就需要牺牲准确性。因此集成学习研究的核心就是学习如何产生并结合“好而不同”的个体学习器。</li>
</ul>
<p>根据个体学习器的生成方式可以分为串行生成的序列化方法和同时生成的并行化方法。前者代表是Boosting(一族可将弱学习器提升为强学习器的算法)，个体学习器存在强依赖关系，所以Boosting算法的机制就是初始训练一个基学习器，然后基于该学习器的表现训练下一个学习器。后者代表是Bagging和随机森林，个体学习器之间不存在强依赖关系。<strong>Boosting族算法最著名的代表就是AdaBoost。</strong></p>
<p>###2. AdaBoost<br>AdaBoost算法有多种推导方式，这里介绍容易理解的additive model，也就是俗称的加性模型$H(x)=\sum_{t=1}^T \alpha_th<em>t(x)$,即基学习器的线性组合。在这里我们利用指数损失函数**$l</em>{exp}(H|D)=E_{x-D}[e^{-f(x)H(x)}]$**替代0/1损失函数作为优化目标，原因就是在不影响分类错误率的前提下，指数损失函数数学性质更好。那么我们的目的就是学习到H(x)令指数损失函数最小化，这里不做细致的公式推导，稍微简单说一下，指数损失函数对H(x)求偏导，再令其等于0求得H(x)的闭式解。<br>机器学习实战关于AdaBoost基于错误提升分类器的性能的算法机制更加通俗易懂。总结下来就是对权重的更新，这里权重分为基于每个基学习器的学习器权重，以及在该学习器学习情况下训练样本的权重。具体运行过程是这样的：训练数据中每个样本对应一个权重，这些权重构成向量D，一开始每个样本权重初始化为相等的值。初始化过程中会基于权重相等的样本训练集训练一个弱分类器并计算其错误率。当我们第二次训练分类器时，会基于上一次的错误率情况对训练样本权重进行调整，分类错误的权重提高，正确的降低，使得我们在第二次训练分类器的时候加强对上一次分类错误的样本的注意力，这样我们就可以根据新的向量D来对训练集进行训练得到第二个分类器，AdaBoost算法也为每个分类器分配了对应的权重值，该值直接依据该分类器的分类性能也就是错误率来计算权重值。按照上述过程迭代，我们会发现AdaBoost就是对基分类器权重以及该分类器对应的样本集的权重集D的迭代更新。那么重点就是如何更新的策略的选择。具体的数学推理见西瓜书P175，其实我觉得西瓜书推导也不具体。。看着挺吃力，数学基础太重要了。</p>
<p>###3. 基于单层决策树构建弱分类器<br>伪代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">将最小错误率minError初始化设为正无穷</div><div class="line"><span class="keyword">for</span>（数据集中的每一个特征）</div><div class="line">    <span class="keyword">for</span>（每一个步长）</div><div class="line">        <span class="keyword">for</span>（每个分类判别策略）</div><div class="line">            建立一个单层决策树并利用加权数据集对它进行测试</div><div class="line">            如果错误率低于minError，则将当前单层决策树设为最佳单层决策树</div><div class="line">返回最佳单层决策树</div></pre></td></tr></table></figure></p>
<ul>
<li><p>这里需要注意的就是循环一是对数据集的特征类型进行循环，循环二的目的则是为了对不同阀值的决策情况进行循环，这里特征是数值型的，因此用步长(计算特征的最大值和最小值求得)来作为阀值的取值情况。第三个循环中则是对具体阀值的判别策略进行循环，比如这里的大于还是小于情形。<br><strong>决策树生成代码具体代码如下：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadSimpleData</span><span class="params">()</span>:</span></div><div class="line">	datMat = matrix([[<span class="number">1.</span> , <span class="number">2.1</span>],</div><div class="line">		[<span class="number">2.</span> , <span class="number">1.1</span>],</div><div class="line">		[<span class="number">1.3</span> , <span class="number">1.</span> ],</div><div class="line">		[<span class="number">1.</span> , <span class="number">1.</span> ],</div><div class="line">		[<span class="number">2.</span> , <span class="number">1.</span> ]])</div><div class="line">	classLables = [<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">-1.0</span>,<span class="number">-1.0</span>,<span class="number">1.0</span>]</div><div class="line">	<span class="keyword">return</span> datMat,classLables</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span><span class="params">(dataMatrix,dimen,threshVal,threshIneq)</span>:</span></div><div class="line">	retArray = ones((shape(dataMatrix)[<span class="number">0</span>],<span class="number">1</span>))</div><div class="line">	<span class="keyword">if</span> threshIneq == <span class="string">'lt'</span>:</div><div class="line">		retArray[dataMatrix[:,dimen] &lt;= threshVal] = <span class="number">-1.0</span></div><div class="line">	<span class="keyword">else</span>:</div><div class="line">		retArray[dataMatrix[:,dimen] &gt; threshVal] = <span class="number">-1.0</span></div><div class="line">	<span class="keyword">return</span> retArray</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span><span class="params">(dataArr,classLabels,D)</span>:</span></div><div class="line">	dataMatrix = mat(dataArr);labelMat = mat(classLabels).T</div><div class="line">	m,n = shape(dataMatrix)</div><div class="line">	numSteps = <span class="number">10.0</span>; bestStump = &#123;&#125;; bestClasEst = mat(zeros((m,<span class="number">1</span>)))</div><div class="line">	minError = inf</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(n):</div><div class="line">		rangeMin = dataMatrix[:,i].min();rangeMax = dataMatrix[:,i].max();</div><div class="line">		stepSize = (rangeMax - rangeMin)/numSteps</div><div class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">-1</span>,int(numSteps)+<span class="number">1</span>):</div><div class="line">			<span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">'lt'</span>,<span class="string">'gt'</span>]:</div><div class="line">				threshVal = (rangeMin + float(j) * stepSize)</div><div class="line">				predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)</div><div class="line">				errArr = mat(ones((m,<span class="number">1</span>)))</div><div class="line">				errArr[predictedVals == labelMat] = <span class="number">0</span></div><div class="line">				weightedError = D.T*errArr</div><div class="line">				<span class="keyword">if</span> weightedError &lt; minError:</div><div class="line">					minError = weightedError</div><div class="line">					bestClasEst = predictedVals.copy()</div><div class="line">					bestStump[<span class="string">'dim'</span>] = i</div><div class="line">					bestStump[<span class="string">'thresh'</span>] = threshVal</div><div class="line">					bestStump[<span class="string">'ineq'</span>] = inequal</div><div class="line">	<span class="keyword">return</span> bestStump,minError,bestClasEst</div></pre></td></tr></table></figure>
</li>
<li><p>stumpClassify()：通过阀值比较对数据进行分类，输入分别为数据集，特征类型，阀值，具体判别策略。也就是该函数选择数据集中某特征类型，然后按照具体的判别策略将特征类型的值与阀值进行比较，最后返回判别过后得到的分类结果。</p>
</li>
<li>buildStump()：该函数就是利用上面介绍的函数来寻找数据集上最佳的单层决策树。了解AdaBoost算法的都应该知道在该函数找到的最佳单层决策树是基于样本权重向量D的，也就是在后来的AdaBoost算法中会基于不同的样本权重向量D进行迭代，每次迭代过程中调用buildStump函数寻找D情形下的最佳单层决策树。从代码<code>weightedError = D.T*errArr</code>中我们也可以发现决定决策树错误率是要经过D计算得到的，作为判定决策树是否最佳的重要影响因素，D就是AdaBoost算法与分类器交互的关键所在。</li>
</ul>
<p>###4. 完整AdaBoost算法的实现<br>伪代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">对每次迭代</div><div class="line">    调用buildStump()函数找到初始化情形下最佳的单层决策树</div><div class="line">    将最佳单层决策树加入到单层决策树组</div><div class="line">    更新该单层决策树的权重值</div><div class="line">    基于该单层决策树的分类情况更新样本权重向量D</div><div class="line">    更新累计类别估计值</div><div class="line">    如果错误率为<span class="number">0</span>则退出循环</div></pre></td></tr></table></figure></p>
<ul>
<li><p>伪代码很好理解，但是这里稍微提一下更新累计类别估计值：我们都知道AdaBoost算法属于集成学习，是将多个弱分类器串行生成，当我们找到第一个弱分类器之后对其进行性能评估，那么第二个分类器找到之后就需要对第一个和第二个的整体性能进行评估，而对多个分类器整体性能的评估就是利用这里的累计类别估计值求出整体错误率。<br><strong>具体的python实现代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span><span class="params">(dataArr,classLabels,numIt=<span class="number">40</span>)</span>:</span></div><div class="line">    weakClassArr = []</div><div class="line">    m = shape(dataArr)[<span class="number">0</span>]</div><div class="line">    D = mat(ones((m,<span class="number">1</span>))/m)   <span class="comment">#init D to all equal</span></div><div class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</div><div class="line">        bestStump,error,classEst = buildStump(dataArr,classLabels,D)<span class="comment">#build Stump</span></div><div class="line">        <span class="comment">#print "D:",D.T</span></div><div class="line">        alpha = float(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/max(error,<span class="number">1e-16</span>)))<span class="comment">#calc alpha, throw in max(error,eps) to account for error=0</span></div><div class="line">        bestStump[<span class="string">'alpha'</span>] = alpha  </div><div class="line">        weakClassArr.append(bestStump)                  <span class="comment">#store Stump Params in Array</span></div><div class="line">        <span class="comment">#print "classEst: ",classEst.T</span></div><div class="line">        expon = multiply(<span class="number">-1</span>*alpha*mat(classLabels).T,classEst) <span class="comment">#exponent for D calc, getting messy</span></div><div class="line">        D = multiply(D,exp(expon))                              <span class="comment">#Calc New D for next iteration</span></div><div class="line">        D = D/D.sum()</div><div class="line">        <span class="comment">#calc training error of all classifiers, if this is 0 quit for loop early (use break)</span></div><div class="line">        aggClassEst += alpha*classEst</div><div class="line">        <span class="comment">#print "aggClassEst: ",aggClassEst.T</span></div><div class="line">        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,<span class="number">1</span>)))</div><div class="line">        errorRate = aggErrors.sum()/m</div><div class="line">        <span class="keyword">print</span> <span class="string">"total error: "</span>,errorRate</div><div class="line">        <span class="keyword">if</span> errorRate == <span class="number">0.0</span>: <span class="keyword">break</span></div><div class="line">    <span class="keyword">return</span> weakClassArr,aggClassEst</div></pre></td></tr></table></figure>
</li>
<li><p>该函数的输入参数分别为数据集，正确的类别标签和用户自己设定的迭代次数。当迭代次数满或者最后错误率为0时返回决策树集。这里的决策树集是一个数组包含多个最佳单层决策树的具体信息。这里还要说一下每个决策树的具体信息包含判别特征类型，判别具体策略(大于或者小于)，判别阀值以及该决策树对应的权重值。</p>
</li>
<li>个人理解抽出算法的三大点：决策树权重alpha，样本权重向量D，错误率累计计算。理解这三点这个算法很容易写出来。其中alpha和D的更新公式的具体数学推导可自行查阅资料感受数学原理的强大，这些更新代码公式并不是平白无故产生的，有着严谨的数学推导(指数损失函数的最优化)。至于错误率累计的那几行代码看懂明白这里评估的错误率怎么求就行。</li>
</ul>
<p>###5. 测试算法：基于AdaBoost的分类<br>之前讲了单个弱分类器的构建以及AdaBoost算法基于单个弱分类器的实现，这里将利用AdaBoost算法对具体实例进行分类来看看算法性能。<br><strong>分类函数代码：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span><span class="params">(datToClass,classifierArr)</span>:</span></div><div class="line">    dataMatrix = mat(datToClass)<span class="comment">#do stuff similar to last aggClassEst in adaBoostTrainDS</span></div><div class="line">    m = shape(dataMatrix)[<span class="number">0</span>]</div><div class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(classifierArr)):</div><div class="line">        classEst = stumpClassify(dataMatrix,classifierArr[i][<span class="string">'dim'</span>],\</div><div class="line">                                 classifierArr[i][<span class="string">'thresh'</span>],\</div><div class="line">                                 classifierArr[i][<span class="string">'ineq'</span>])<span class="comment">#call stump classify</span></div><div class="line">        aggClassEst += classifierArr[i][<span class="string">'alpha'</span>]*classEst</div><div class="line">        <span class="keyword">print</span> aggClassEst</div><div class="line">    <span class="keyword">return</span> sign(aggClassEst)</div></pre></td></tr></table></figure></p>
<ul>
<li>想不通为什么测试说字典索引不能用字符串？wtf。。</li>
</ul>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/fclefang/JavaScript/SVM(1)/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          SVM(1)
        
      </div>
    </a>
  
  
    <a href="/fclefang/JavaScript/Java8/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Java8</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">Share to: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="JavaScript/AdaBoost" data-title="AdaBoost" data-url="http://www.fclef.me/fclefang/JavaScript/AdaBoost/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"fclef"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Fclefang
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>