<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>tree-regression | fclefang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在前面总结的线性回归算法中都需要拟合所有的样本点，当然除了回归类中的特例LWLR。抛开更加复杂的计算不谈，面对很多现实问题，全局线性回归模型来拟合所有数据样本是不可能的。那么是否可以对数据集进行选择，得到适合进行线性回归模型拟合的子集。与LWLR不同，这里利用决策树的方法对数据集进行结构化然后切分得到理想的子集。接下来会介绍CART(Classification And Regression Tr">
<meta property="og:type" content="article">
<meta property="og:title" content="tree-regression">
<meta property="og:url" content="http://www.fclef.me/fclefang/JavaScript/tree-regression/index.html">
<meta property="og:site_name" content="fclefang">
<meta property="og:description" content="在前面总结的线性回归算法中都需要拟合所有的样本点，当然除了回归类中的特例LWLR。抛开更加复杂的计算不谈，面对很多现实问题，全局线性回归模型来拟合所有数据样本是不可能的。那么是否可以对数据集进行选择，得到适合进行线性回归模型拟合的子集。与LWLR不同，这里利用决策树的方法对数据集进行结构化然后切分得到理想的子集。接下来会介绍CART(Classification And Regression Tr">
<meta property="og:updated_time" content="2016-12-07T15:21:28.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tree-regression">
<meta name="twitter:description" content="在前面总结的线性回归算法中都需要拟合所有的样本点，当然除了回归类中的特例LWLR。抛开更加复杂的计算不谈，面对很多现实问题，全局线性回归模型来拟合所有数据样本是不可能的。那么是否可以对数据集进行选择，得到适合进行线性回归模型拟合的子集。与LWLR不同，这里利用决策树的方法对数据集进行结构化然后切分得到理想的子集。接下来会介绍CART(Classification And Regression Tr">
  
    <link rel="alternative" href="/atom.xml" title="fclefang" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/timg.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/timg.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Fclefang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">开心自由最重要</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>About</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/categories">分类</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/MR-Fclef" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/fang-xiang-yan" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/GIS/" style="font-size: 12.5px;">GIS</a> <a href="/tags/JavaScript/" style="font-size: 15px;">JavaScript</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MachineLearning/" style="font-size: 20px;">MachineLearning</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/Node-js/" style="font-size: 12.5px;">Node.js</a> <a href="/tags/gossip/" style="font-size: 10px;">gossip</a> <a href="/tags/java/" style="font-size: 17.5px;">java</a> <a href="/tags/parking/" style="font-size: 10px;">parking</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">CIT（2012-2016）,GuiLin Elec(2016-2019).认真做好应该做的每一件事。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Fclefang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/img/timg.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Fclefang</h1>
			</hgroup>
			
			<p class="header-subtitle">开心自由最重要</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/categories">分类</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/MR-Fclef" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/fang-xiang-yan" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-JavaScript/tree-regression" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/fclefang/JavaScript/tree-regression/" class="article-date">
  	<time datetime="2016-11-26T07:55:01.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      tree-regression
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/tree-regression/">tree-regression</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在前面总结的线性回归算法中都需要拟合所有的样本点，当然除了回归类中的特例LWLR。抛开更加复杂的计算不谈，面对很多现实问题，全局线性回归模型来拟合所有数据样本是不可能的。那么是否可以对数据集进行选择，得到适合进行线性回归模型拟合的子集。与LWLR不同，这里利用决策树的方法对数据集进行结构化然后切分得到理想的子集。接下来会介绍CART(Classification And Regression Trees)的树构建算法，既可以用于分类又可以用于回归。<br><a id="more"></a></p>
<hr>
<h2 id="1-ID3和CART"><a href="#1-ID3和CART" class="headerlink" title="1.ID3和CART"></a>1.ID3和CART</h2><p>ID3每次选取当前最佳的特征来分割数据，并按照该特征的所有可能取值来切分，只能处理离散特征值，对于连续性不能直接处理(可以先将连续性转化为离散型，但是会影响连续性包含的数据内在性质)。<br>CART是一个著名的树构建算法，使用二元切分法来处理连续性变量。具体做法就是如果特征值大于定值就走左子树，否则走右子树。</p>
<ul>
<li>python可以直接使用字典来存储树结构而不用另外自定义一个类。<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">treeNode</span><span class="params">()</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,feat,val,right,left)</span>:</span></div><div class="line">		featureToSplitOn = feat</div><div class="line">		valueOfSplit = val</div><div class="line">		rightBranch = right</div><div class="line">		leftBranch = left</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>构建树createTree()的伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">找到最佳的待切分特征：</div><div class="line">    如果该节点不能再分，将该节点存为叶节点</div><div class="line">    执行二元切分</div><div class="line">    在右子树调用createTree()方法</div><div class="line">    在左子树调用createTree()方法</div></pre></td></tr></table></figure>
</li>
<li><p>CART代码的实现代码：<br>(1).binSplitDataSet()函数，三个参数分别为数据集合，待切分特征以及该特征的某个值。在给定特征以及特征值的情况下，该函数通过数组过滤方式切分数据集合得到左右两个数据子集并返回。这里介绍一下nonzero()函数，这是numpy库下的一个函数，输入参数数组或者矩阵，函数以矩阵形式返回输入值中非零元素的信息，信息包括两个矩阵分别表示相应维度上非零元素所在的行标号和列标号。另外再多说一局如果按照机器学习实战书上的那个测试的话注意将切分函数中mat0和mat1最后的<code>[0]</code>给删除测试，否则只会返回切分后子集矩阵的第一维样例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span>      <span class="comment">#general function to parse tab -delimited floats</span></div><div class="line">    dataMat = []                <span class="comment">#assume last column is target value</span></div><div class="line">    fr = open(fileName)</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</div><div class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">        fltLine = map(float,curLine) <span class="comment">#map all elements to float()</span></div><div class="line">        dataMat.append(fltLine)</div><div class="line">    <span class="keyword">return</span> dataMat</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">binSplitDataSet</span><span class="params">(dataSet, feature, value)</span>:</span></div><div class="line">    mat0 = dataSet[nonzero(dataSet[:,feature] &gt; value)[<span class="number">0</span>],:][<span class="number">0</span>]</div><div class="line">    mat1 = dataSet[nonzero(dataSet[:,feature] &lt;= value)[<span class="number">0</span>],:][<span class="number">0</span>]</div><div class="line">    <span class="keyword">return</span> mat0,mat1</div></pre></td></tr></table></figure>
</li>
</ul>
<p>(2)createTree函数是一个递归函数，该函数首先尝试将数据集分为两部分，切分函数chooseBestSplit()。如果满足停止条件则切分函数返回none和模型值，当然如果构建的是回归树则返回的一个实值，若构建的模型树则返回一个线性方程。如果不满足停止条件，切分函数将创建新的字典并将数据集分为两份并在数据集上继续递归调用createTree函数。代码实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, leafType=regLeaf, errType=regErr, ops=<span class="params">(<span class="number">1</span>,<span class="number">4</span>)</span>)</span>:</span><span class="comment">#assume dataSet is NumPy Mat so we can array filtering</span></div><div class="line">    feat, val = chooseBestSplit(dataSet, leafType, errType, ops)<span class="comment">#choose the best split</span></div><div class="line">    <span class="keyword">if</span> feat == <span class="keyword">None</span>: <span class="keyword">return</span> val <span class="comment">#if the splitting hit a stop condition return val</span></div><div class="line">    retTree = &#123;&#125;</div><div class="line">    retTree[<span class="string">'spInd'</span>] = feat</div><div class="line">    retTree[<span class="string">'spVal'</span>] = val</div><div class="line">    lSet, rSet = binSplitDataSet(dataSet, feat, val)</div><div class="line">    retTree[<span class="string">'left'</span>] = createTree(lSet, leafType, errType, ops)</div><div class="line">    retTree[<span class="string">'right'</span>] = createTree(rSet, leafType, errType, ops)</div><div class="line">    <span class="keyword">return</span> retTree</div></pre></td></tr></table></figure></p>
<p>(3).<code>chooseBestSplit(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):</code>主要用最佳方式切分数据集和生成相应的叶叶节点，其中最佳切分方式利用数据总方差来选择，函数的errType参数则是该总方差计算函数的引用，leafType是对创建叶节点函数的引用，ops是用户定义的参数构成的元组，用以完成树的构建。一开始ops设定了tolS和tolN两个值，这两个值用户指定用来控制函数的停止时机。tolS是容许的误差下降值，tolN是切分的最少样本数。另外需要注意切分函数在三种情况下不会切分而是直接创建叶节点。<br>伪代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">对每个特征：</div><div class="line">    对每个特征值：</div><div class="line">        将数据集切分成两份</div><div class="line">        计算切分的误差</div><div class="line">        如果当前误差小于当前最小误差，则当前切分设置为最佳切分</div><div class="line">返回最佳切分的特征和阀值</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">regLeaf</span><span class="params">(dataSet)</span>:</span><span class="comment">#returns the value used for each leaf</span></div><div class="line">    <span class="keyword">return</span> mean(dataSet[:,<span class="number">-1</span>])</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">regErr</span><span class="params">(dataSet)</span>:</span></div><div class="line">    <span class="keyword">return</span> var(dataSet[:,<span class="number">-1</span>]) * shape(dataSet)[<span class="number">0</span>]</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestSplit</span><span class="params">(dataSet, leafType=regLeaf, errType=regErr, ops=<span class="params">(<span class="number">1</span>,<span class="number">4</span>)</span>)</span>:</span></div><div class="line">    tolS = ops[<span class="number">0</span>]; tolN = ops[<span class="number">1</span>]</div><div class="line">    <span class="comment">#if all the target variables are the same value: quit and return value</span></div><div class="line">    <span class="keyword">if</span> len(set(dataSet[:,<span class="number">-1</span>].T.tolist()[<span class="number">0</span>])) == <span class="number">1</span>: <span class="comment">#exit cond 1</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, leafType(dataSet)</div><div class="line">    m,n = shape(dataSet)</div><div class="line">    <span class="comment">#the choice of the best feature is driven by Reduction in RSS error from mean</span></div><div class="line">    S = errType(dataSet)</div><div class="line">    bestS = inf; bestIndex = <span class="number">0</span>; bestValue = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> featIndex <span class="keyword">in</span> range(n<span class="number">-1</span>):</div><div class="line">        <span class="keyword">for</span> splitVal <span class="keyword">in</span> set(dataSet[:,featIndex]):</div><div class="line">            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)</div><div class="line">            <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN): <span class="keyword">continue</span></div><div class="line">            newS = errType(mat0) + errType(mat1)</div><div class="line">            <span class="keyword">if</span> newS &lt; bestS: </div><div class="line">                bestIndex = featIndex</div><div class="line">                bestValue = splitVal</div><div class="line">                bestS = newS</div><div class="line">    <span class="comment">#if the decrease (S-bestS) is less than a threshold don't do the split</span></div><div class="line">    <span class="keyword">if</span> (S - bestS) &lt; tolS: </div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, leafType(dataSet) <span class="comment">#exit cond 2</span></div><div class="line">    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)</div><div class="line">    <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN):  <span class="comment">#exit cond 3</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, leafType(dataSet)</div><div class="line">    <span class="keyword">return</span> bestIndex,bestValue<span class="comment">#returns the best feature to split on</span></div><div class="line">                              <span class="comment">#and the value used for that split</span></div></pre></td></tr></table></figure>
<ul>
<li>切分函数代码分析中的几点注意：之前说到3种情况会直接返回生成叶节点，如果三种情况都不满足意味着需要切分于是返回切分的特征及其特征值。另外<code>len(set(dataSet[:,-1].T.tolist()[0])) == 1</code>这句代码一开始困扰了一会，经过对tolist和set的文档查阅，后来试用了一个小数据集来一步步调试这句代码处理数据的具体运行结果才明白，其实就是监测切分后的特征值分布情况，返回剩余的特征值中数值不相等的个数， 当特征值都是相同的则这句代码会返回数字1意味着不需要切分于是就直接返回none了。</li>
<li><code>for splitVal in set(dataSet[:,featIndex])</code>：在调试的代码的时候这句报错<code>unhashable type: &#39;matrix&#39;</code>。需要牢记的第一条就是dict的key必须是不可变对象。这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这个通过key计算位置的算法称为哈希算法（Hash）。要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key。set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。要创建一个set，需要提供一个list作为输入集合。所以这里改成<code>splitVal in set(dataSet[:,featIndex].T.tolist()[0]):</code>。关于python字典列表等更多知识参考可以<a href="http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868193482529754158abf734c00bba97c87f89a263b000" target="_blank" rel="external">廖雪峰官方网站</a>。这句代码改过来之后就可以对数据集构建会归树了。</li>
</ul>
<hr>
<h2 id="2-剪枝技术"><a href="#2-剪枝技术" class="headerlink" title="2.剪枝技术"></a>2.剪枝技术</h2><p>剪枝pruning是决策树学习算法处理过拟合的主要方法，在决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会在成决策树分支过多，以致于把训练集自身的一些特点当做所有数据都具有的一般性质而导致过拟合，因此可通过主动去掉一些分支(降低决策树模型的复杂度)来降低过拟合的风险。</p>
<ul>
<li>预剪枝：指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来泛化性能的提升，则停止划分并将当前结点标记为叶节点。上一节的切分函数中的提前终止划分条件就是某种意义上的预剪枝，对当前结点划分后的误差给定一个容忍度，当发现该划分并不能降低误差到一定程度上时就直接返回，不对结点进行划分。值得注意的是，预剪枝降低了过拟合风险甚至显著降低了计算开销，然而从另一方面来看，有些分支虽然当前划分并不能提升泛化性能甚至还降低性能，但是在该划分基础上的后续划分却有可能大幅提升泛化性能的，这也算预剪枝的缺陷。</li>
<li>后剪枝：指先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来泛化性能的提升则将该子树替换为叶结点。比起预剪枝导致一些可能带来泛化性能提升的结点划分被提前终止，一般情况下，后剪枝会给决策树保留更多的分支，一定程度避免了欠拟合的风险，所以算是一种更加理想的剪枝方法。虽然效果比预剪枝好，但是很明显计算开销比起预剪枝要大得多。</li>
<li><strong>下面详细介绍CART剪枝算法</strong>：在西瓜书中是通过精度的计算来进行剪枝的，书中讲得非常详细，这里不多说，下面是对李航统计学习决策树剪枝算法的分析。<br>李航书上介绍的是通过极小化决策树整体的损失函数或者说代价函数来实现。首先什么是损失函数，这里记为$C_a(T)=C(T)+a|T|$。其中C(T)表示模型对训练数据的预测误差即模型与训练数据的拟合程度，可以通过求经验熵来表示；$|T|$表示模型的复杂度或者也可以看成子树的叶结点个数也象征着模型复杂度。看到这里我想应该会联想到其他模型，损失函数也是通过模型与数据的拟合程度和模型复杂度来表示。然后这里的a也就是权衡而这之间的一个用户设置的参数，当然这里需要清晰认识到a的不同取值对应着子树的不同意义。算法分为两步，第一步从CART生成算法产生的决策树底端开始不断剪枝，直到根结点，形成一个子树序列。第二步通过交叉验证法利用独立的验证数据集对子序列进行测试，从中选择最优子树。<br>CART剪枝算法伪代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">输入：CART生成算法生成的决策树和用于测试子树序列的验证数据集。</div><div class="line">输出：最优决策树</div><div class="line">李航统计学习P73</div></pre></td></tr></table></figure>
</li>
</ul>
<p>把这一块搞明白继而理解实战中的后剪枝算法代码。应该是按照西瓜书中所说的精度为依据进行剪枝的。<br>后剪枝函数<code>prune()</code>的伪代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">基于已有的树切分测试数据：</div><div class="line">    如果存在任一子集是一棵树，则在该子集递归剪枝过程</div><div class="line">    计算将当前两个叶结点合并后的误差</div><div class="line">    计算不合并的误差</div><div class="line">    如果合并会降低误差则将叶结点合并</div></pre></td></tr></table></figure></p>
<p>实现代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">isTree</span><span class="params">(obj)</span>:</span></div><div class="line">    <span class="keyword">return</span> (type(obj).__name__==<span class="string">'dict'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMean</span><span class="params">(tree)</span>:</span></div><div class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">'right'</span>]): tree[<span class="string">'right'</span>] = getMean(tree[<span class="string">'right'</span>])</div><div class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">'left'</span>]): tree[<span class="string">'left'</span>] = getMean(tree[<span class="string">'left'</span>])</div><div class="line">    <span class="keyword">return</span> (tree[<span class="string">'left'</span>]+tree[<span class="string">'right'</span>])/<span class="number">2.0</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">prune</span><span class="params">(tree, testData)</span>:</span></div><div class="line">    <span class="keyword">if</span> shape(testData)[<span class="number">0</span>] == <span class="number">0</span>: <span class="keyword">return</span> getMean(tree) <span class="comment">#if we have no test data collapse the tree</span></div><div class="line">    <span class="keyword">if</span> (isTree(tree[<span class="string">'right'</span>]) <span class="keyword">or</span> isTree(tree[<span class="string">'left'</span>])):<span class="comment">#if the branches are not trees try to prune them</span></div><div class="line">        lSet, rSet = binSplitDataSet(testData, tree[<span class="string">'spInd'</span>], tree[<span class="string">'spVal'</span>])</div><div class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">'left'</span>]): tree[<span class="string">'left'</span>] = prune(tree[<span class="string">'left'</span>], lSet)</div><div class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">'right'</span>]): tree[<span class="string">'right'</span>] =  prune(tree[<span class="string">'right'</span>], rSet)</div><div class="line">    <span class="comment">#if they are now both leafs, see if we can merge them</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isTree(tree[<span class="string">'left'</span>]) <span class="keyword">and</span> <span class="keyword">not</span> isTree(tree[<span class="string">'right'</span>]):</div><div class="line">        lSet, rSet = binSplitDataSet(testData, tree[<span class="string">'spInd'</span>], tree[<span class="string">'spVal'</span>])</div><div class="line">        errorNoMerge = sum(power(lSet[:,<span class="number">-1</span>] - tree[<span class="string">'left'</span>],<span class="number">2</span>)) +\</div><div class="line">            sum(power(rSet[:,<span class="number">-1</span>] - tree[<span class="string">'right'</span>],<span class="number">2</span>))</div><div class="line">        treeMean = (tree[<span class="string">'left'</span>]+tree[<span class="string">'right'</span>])/<span class="number">2.0</span></div><div class="line">        errorMerge = sum(power(testData[:,<span class="number">-1</span>] - treeMean,<span class="number">2</span>))</div><div class="line">        <span class="keyword">if</span> errorMerge &lt; errorNoMerge: </div><div class="line">            <span class="keyword">print</span> <span class="string">"merging"</span></div><div class="line">            <span class="keyword">return</span> treeMean</div><div class="line">        <span class="keyword">else</span>: <span class="keyword">return</span> tree</div><div class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> tree</div></pre></td></tr></table></figure></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/fclefang/JavaScript/发音拼写的概率模型/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          发音拼写的概率模型
        
      </div>
    </a>
  
  
    <a href="/fclefang/JavaScript/语音转换/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">语音转换</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">Share to: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="JavaScript/tree-regression" data-title="tree-regression" data-url="http://www.fclef.me/fclefang/JavaScript/tree-regression/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"fclef"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2018 Fclefang
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>